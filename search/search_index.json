{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"From-Scratch Foundations","text":"<p>First-principles implementations, structured notes, and experiments for AI research \u2014 all built from scratch.</p> <ul> <li> <p> Math</p> <p>Linear algebra, probability, optimization, information theory.</p> <p> Browse notes</p> </li> <li> <p> Deep Learning</p> <p>Architectures, training dynamics, and from-scratch builds.</p> <p> Browse notes</p> </li> <li> <p> Reinforcement Learning</p> <p>MDPs, policy gradients, bandits, and planning.</p> <p> Browse notes</p> </li> <li> <p> NLP &amp; LLMs</p> <p>Transformers, tokenization, alignment, and evaluation.</p> <p> Browse notes</p> </li> <li> <p> DSA</p> <p>Data structures, algorithms, and complexity analysis.</p> <p> Browse notes</p> </li> </ul> <p> Quiet persistence brings clarity. </p>"},{"location":"reinforcement-learning/","title":"Reinforcement Learning","text":"<p>Notes and implementations covering MDPs, dynamic programming, policy gradients, contextual bandits, and planning algorithms.</p>"},{"location":"reinforcement-learning/#notes","title":"Notes","text":"Topic Status MDP fundamentals Policy gradient methods Contextual bandits (VW) Monte Carlo tree search <p>Reading queue</p> <ul> <li>Sutton &amp; Barto Ch. 1\u20135</li> <li>Lattimore &amp; Szepesv\u00e1ri (Bandit Algorithms)</li> <li>Agarwal et al. (RL: Theory and Algorithms)</li> </ul>"}]}